<!DOCTYPE html>
<html lang="" xml:lang="" xmlns="http://www.w3.org/1999/xhtml">

<head>
    <meta charset="utf-8" />
    <meta content="width=device-width, initial-scale=1" name="viewport" />
    <title>
        Enhanced Kalman with Adaptive Appearance Motion SORT for Grounded Generic Multiple Object Tracking
    </title>
    <meta content="Open-GMOT" property="og:title" />
    <meta content="A typical pipeline for multi-object tracking (MOT) is to use a detector for object localization, and following re-identification (re-ID) for object association. This pipeline is partially motivated by recent progress in both object detec- tion and re-ID, and partially motivated by biases in existing tracking datasets, where most objects tend to have distin- guishing appearance and re-ID models are sufficient for es- tablishing associations. In response to such bias, we would like to re-emphasize that methods for multi-object tracking should also work when object appearance is not sufficiently discriminative. To this end, we propose a large-scale dataset for multi-human tracking, where humans have similar appearance, diverse motion and extreme articulation. As the dataset contains mostly group dancing videos, we name it “DanceTrack”. We expect DanceTrack to provide a better platform to develop more MOT algorithms that rely less on visual discrimination and depend more on motion analysis. We benchmark several state-of-the-art trackers on our dataset and observe a significant performance drop on DanceTrack when compared against existing benchmarks." name="description" property="og:description" />
    <meta content="https://github.com/DanceTrack" property="og:url" />
    <meta name="keywords" content="Generic Multi-Object Tracking in Uniform Appearance and Diverse Motion">

    <link rel="stylesheet" href="css/style.css">
    <link rel="stylesheet" href="css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
    <script defer src="js/fontawesome.all.min.js"></script>
    <style>
        table {
            width: 100%;
            border-collapse: collapse;
        }

        caption {
            padding-top: 3em;
            margin-bottom: 0.5em;
            font-weight: bold;
        }

        th, td {
            border: 1px solid black;
            padding: 5px;
            text-align: center;
        }

        .checkmark {
            font-family: Arial, sans-serif;
            font-weight: bold;
            color: green;
        }
        .xmark {
            font-family: Arial, sans-serif;
            font-weight: bold;
            color: red;
        }

        .asparagus30 { background-color: #88B04B; } /* Replace with actual color */
        .almond30 { background-color: #EFDECD; } /* Replace with actual color */
        .almond50 { background-color: #e6ceb6; }
        .babyblue20 { background-color: #9adaf8; } /* Replace with actual color */
        .babyblue50 { background-color: #77c7ec; }
        .aureolin20 { background-color: #FDEE00; }
        .aureolin50 { background-color: #ebdd14; } /* Replace with actual color */

        .sot { background-color: #84a5bb; } /* Airforce blue */
        .mot { background-color: rgb(53%, 66%, 42%); } /* Almond */
        .gsot { background-color: #8fd2f0; } /* Baby blue */
        .gmot { background-color: #f4e954; } /* Aureolin */

        .image-container {
            display: flex;
        }

        /* Create three equal columns that sits next to each other */
        .image-content {
            margin: 10px;
            flex: 1;
            text-align: center !important;
        }

        .pre-container {
            overflow: auto; /* Enable scrolling if the content overflows */
            text-align: left;
            white-space: pre-wrap; /* Allow long lines to wrap within the container */
            width: calc(100%/2 - 20px); /* Prevent the <pre> from exceeding the parent's width */
            max-height: 100%; /* Prevent the <pre> from exceeding the parent's height */
        }

        .image-json-container {
            display: flex;
            height: 220px;
            align-items: center;
            margin-bottom: 20px;
            padding: 10px 0 0 0;
        }

        .image-dataset {
            max-height: 100%;
            object-fit: cover;
            padding: 0 0 12px 0;
        }

        .json-dataset {
            flex-grow: 1; /* Allow the text to take up remaining space */
            overflow: auto; /* Add overflow property for text scrolling if needed */
            text-align: left;
            height: 96%;
            white-space: pre-line; /* Preserve whitespace in the <pre> tag */
        }
    </style>
</head>

<body>
    <div class="navbar">
        <h3>G2MOT demo website</h3>
        <ul>
            <li><a href="index.html">Home</a></li>
            <li><a href="result.html">Result</a></li>
            <li><a href="code.html">Code</a></li>
            <li><a href="dataset.html">Dataset</a></li>
        </ul>
        <script>
            // Get the current URL
            var currentURL = window.location.href;
        
            // Select all navigation links
            var navLinks = document.querySelectorAll('.navbar a');
        
            // Loop through the links to find the active one
            for (var i = 0; i < navLinks.length; i++) {
                var linkURL = navLinks[i].href;
        
                // Check if the current URL contains the link's URL
                if (currentURL.indexOf(linkURL) !== -1) {
                    // Add the "active" class to the link
                    navLinks[i].classList.add('active');
                }
            }
        </script>
    </div>

    <div class="n-article">
        <h2 class="dataset" id="dataset">
           Dataset
        </h2>
        <table>
            <caption>Comparison of <strong>existing datasets</strong> of SOT, MOT, GSOT, GMOT. "#" represents the quantity of the respective items. <strong>Cat.</strong>, <strong>Vid.</strong> denote Categories and Videos. <strong>Obj.</strong>: average number of objects per frame. <strong>App.</strong>: appearance similarity (%) between objects in a frame, calculated by the average cosine similarity of objects in the same frame; <strong>Den.</strong> density of objects in a frame, computed by the maximum number of objects at the same pixel. <strong>Occ.</strong>: occlusion between objects in a frame, represented by the average ratio of IoU (%) of the bounding boxes in the same frame; <strong>Mot.</strong>: motion speed of objects in a video, calculated by the average ratio of the IoU (%) of the bounding boxes in the same track in consecutive frames.</caption>
            <thead>
                <tr>
                    <th>Datasets</th>
                    <th>Task</th>
                    <th>NLP</th>
                    <th>#Cat.</th>
                    <th>#Vid.</th>
                    <th>#Frames</th>
                    <th>#Tracks</th>
                    <th>#Boxs</th>
                    <th>Obj.</th>
                    <th>App.</th>
                    <th>Den.</th>
                    <th>Occ.</th>
                    <th>Mot.</th>
                </tr>
            </thead>
            <tbody>
                <tr class="sot">
                    <td>OTB2013</td>
                    <td>SOT</td>
                    <td>✗</td>
                    <td>10</td>
                    <td>51</td>
                    <td>29K</td>
                    <td>51</td>
                    <td>29K</td>
                    <td>--</td>
                    <td>--</td>
                    <td>--</td>
                    <td>--</td>
                    <td>--</td>
                </tr>
                <tr class="sot">
                    <td>VOT2017</td>
                    <td>SOT</td>
                    <td>✗</td>
                    <td>24</td>
                    <td>60</td>
                    <td>21K</td>
                    <td>60</td>
                    <td>21K</td>
                    <td>--</td>
                    <td>--</td>
                    <td>--</td>
                    <td>--</td>
                    <td>--</td>
                </tr>
                <tr class="sot">
                    <td>TrackingNet</td>
                    <td>SOT</td>
                    <td>✗</td>
                    <td>21</td>
                    <td>31K</td>
                    <td>14M</td>
                    <td>31K</td>
                    <td>14M</td>
                    <td>--</td>
                    <td>--</td>
                    <td>--</td>
                    <td>--</td>
                    <td>--</td>
                </tr>
                <tr class="mot">
                    <td>MOT17</td>
                    <td>MOT</td>
                    <td>✗</td>
                    <td>1</td>
                    <td>14</td>
                    <td>11.2K</td>
                    <td>1.3K</td>
                    <td>0.3M</td>
                    <td>39(35)</td>
                    <td>62(10)</td>
                    <td>3.85(1.50)</td>
                    <td>14(16)</td>
                    <td>94(11)</td>
                </tr>
                <tr class="mot">
                    <td>MOT20</td>
                    <td>MOT</td>
                    <td>✗</td>
                    <td>1</td>
                    <td>8</td>
                    <td>13.41K</td>
                    <td>3.45K</td>
                    <td>1.65M</td>
                    <td>150(70)</td>
                    <td>68(8)</td>
                    <td>6.42(1.20)</td>
                    <td>15(15)</td>
                    <td>96(4)</td>
                </tr>
                <tr class="mot">
                    <td>Omni-MOT</td>
                    <td>MOT</td>
                    <td>✗</td>
                    <td>1</td>
                    <td>--</td>
                    <td>14M+</td>
                    <td>250K</td>
                    <td>110M</td>
                    <td>--</td>
                    <td>--</td>
                    <td>--</td>
                    <td>--</td>
                    <td>--</td>
                </tr>
                <tr class="mot">
                    <td>DanceTrack</td>
                    <td>MOT</td>
                    <td>✗</td>
                    <td>1</td>
                    <td>100</td>
                    <td>105K</td>
                    <td>990</td>
                    <td>--</td>
                    <td>9(5)</td>
                    <td>77(7)</td>
                    <td>2.67(0.99)</td>
                    <td>21(17)</td>
                    <td>90(9)</td>
                </tr>
                <tr class="mot">
                    <td>TAO</td>
                    <td>MOT</td>
                    <td>✗</td>
                    <td>833</td>
                    <td>2.9K</td>
                    <td>2.6M</td>
                    <td>17.2K</td>
                    <td>333K</td>
                    <td>3(2)</td>
                    <td>69(7)</td>
                    <td>1.82(0.76)</td>
                    <td>11(14)</td>
                    <td>49(34)</td>
                </tr>
                <tr class="mot">
                    <td>SportsMOT</td>
                    <td>MOT</td>
                    <td>✗</td>
                    <td>1</td>
                    <td>240</td>
                    <td>150K</td>
                    <td>3.4K</td>
                    <td>1.62M</td>
                    <td>11(3)</td>
                    <td>73(8)</td>
                    <td>2.44(0.80)</td>
                    <td>18(17)</td>
                    <td>80(16)</td>
                </tr>
                <tr class="gsot">
                    <td>GOT-10k</td>
                    <td>GSOT</td>
                    <td>✗</td>
                    <td>563</td>
                    <td>10K</td>
                    <td>1.5M</td>
                    <td>10K</td>
                    <td>1.5M</td>
                    <td>--</td>
                    <td>--</td>
                    <td>--</td>
                    <td>--</td>
                    <td>--</td>
                </tr>
                <tr class="gsot">
                    <td>Fish</td>
                    <td>GSOT</td>
                    <td>✗</td>
                    <td>1</td>
                    <td>1.6K</td>
                    <td>527.2K</td>
                    <td>8.25K</td>
                    <td>516K</td>
                    <td>--</td>
                    <td>--</td>
                    <td>--</td>
                    <td>--</td>
                    <td>--</td>
                </tr>
                <tr class="gmot">
                    <td>AnimalTrack</td>
                    <td>GMOT</td>
                    <td>✗</td>
                    <td>10</td>
                    <td>58</td>
                    <td>24.7K</td>
                    <td>1.92K</td>
                    <td>429K</td>
                    <td>17(9)</td>
                    <td>72(8)</td>
                    <td>3.13(1.22)</td>
                    <td>15(15)</td>
                    <td>91(11)</td>
                </tr>
                <tr class="gmot">
                    <td>GMOT-40</td>
                    <td>GMOT</td>
                    <td>✗</td>
                    <td>10</td>
                    <td>40</td>
                    <td>9K</td>
                    <td>2.02K</td>
                    <td>256K</td>
                    <td>24(17)</td>
                    <td>71(9)</td>
                    <td>2.56(0.88)</td>
                    <td>11(12)</td>
                    <td>43(44)</td>
                </tr>
                <tr class="sot">
                    <td>LaSOT</td>
                    <td>SOT</td>
                    <td>coarse</td>
                    <td>70</td>
                    <td>1.4K</td>
                    <td>3.52M</td>
                    <td>1.4K</td>
                    <td>3.52M</td>
                    <td>--</td>
                    <td>--</td>
                    <td>--</td>
                    <td>--</td>
                    <td>--</td>
                </tr>
                <tr class="sot">
                    <td>TNL2K</td>
                    <td>SOT</td>
                    <td>coarse</td>
                    <td>--</td>
                    <td>2K</td>
                    <td>1.24M</td>
                    <td>2K</td>
                    <td>1.24M</td>
                    <td>--</td>
                    <td>--</td>
                    <td>--</td>
                    <td>--</td>
                    <td>--</td>
                </tr>
                <tr class="mot">
                    <td>Refer-KITTI</td>
                    <td>MOT</td>
                    <td>coarse</td>
                    <td>2</td>
                    <td>18</td>
                    <td>6.65K</td>
                    <td>637</td>
                    <td>28.72K</td>
                    <td>5(4)</td>
                    <td>65(6)</td>
                    <td>1.78(0.74)</td>
                    <td>11(11)</td>
                    <td>73(21)</td>
                </tr>
                <tr class="gmot">
                    <td><strong>G<sup>2</sup>MOT (Ours)</strong></td>
                    <td>GMOT</td>
                    <td>fine</td>
                    <td>20</td>
                    <td>253</td>
                    <td>157.2K</td>
                    <td>5.84K</td>
                    <td>1.87M</td>
                    <td>12(5)</td>
                    <td>74(8)</td>
                    <td>2.65(0.95)</td>
                    <td>18(16)</td>
                    <td>84(14)</td>
                </tr>
            </tbody>
        </table>
        
        <div>
            <p>Combining datasets in object tracking offers strategic advantages. First, individual tracking datasets focus on specific challenges. Second, merging tracking datasets yields diverse challenges requiring tracking models to efficiently in varied scenarios. Therefore, by combining datasets, we can evaluate the tracking models' ability to deal with diverse scenarios e.g. object movements, density, similar appearance, and occlusion which are in line with the goal of the GMOT challenge. Finally, our ultimate objective is to <em>propose a new paradigm</em> for GMOT and create a <em>challenging benchmark dataset under various demanding real-world scenarios</em>.</p>
            <p>Each video in these datasets has been carefully annotated with several details:</p>
            <ul>
                <p style="font-weight: bold; font-style: italic;">For text label:</p> 
                <li><strong>class_name:</strong> Represents the common name of the object class.</li>
                <li><strong>type (superset|subset):</strong> Indicates whether the object belongs to a "superset" category, grouping "coarse category" (e.g., horse), or a "subset" category, allowing for finer categorization (e.g., horse on ground).</li>
                <li><strong>synonyms:</strong> Offers alternative terms or phrases for the class name.</li>
                <li><strong>definition:</strong> Describe the object's visual characteristics.</li>
                <li><strong>attributes:</strong> encompasses a list of attributes used to distinguish objects within the "superset".</li>
                <li><strong>caption:</strong> Manually crafted comprehensive description providing detailed information about the tracked objects.</li>
                <li><strong>track_path:</strong> The exact tracking path is stored separately, following the standard format for multiple object tracking challenges.</li>
                <p style="font-weight: bold; font-style: italic;">For track label:</p>
                <p>each line will contain 9 elements, seperated by commas</p>
                <p style="color: red;">&lt;frame&gt;, &lt;id&gt;, &lt;bb_left&gt;, &lt;bb_top&gt;, &lt;bb_width&gt;, &lt;bb_height&gt;, &lt;conf&gt;, &lt;x&gt;, &lt;y&gt;</p>
                <li><b>frame:</b> index of frame in video sequence</li>
                <li><b>id</b>: id of object accord to tracker</li>
                <li><b>bb_left:</b> x coordinate for top left</li>
                <li><b>bb_top:</b> y coordinate for top left</li>
                <li><b>bb_width:</b> width of the box that contains object</li>
                <li><b>bb_height:</b> height of the box that contains object</li>
                <li><b>conf:</b> confidence score but get 1 as default</li>
                <li><b>x:</b> get 1 as default</li>
                <li><b>y:</b> get 1 as default</li>
            </ul>
            <p>The annotations are formatted in JSON, and we provide examples to illustrate how they are structured. This data, prepared by 4 annotators, will be shared publicly.</p>
            <div class="image-container">
                <pre class="pre-container" style="border-right: 1px solid #ffffff;">
<b>Text label for referring with specific attributes</b>
{
    id: "",
    video_id: "",
    is_eval: "",
    type: "",
    superset_idx: "",
    class_name: "",
    synonyms:[],
    definition: "",
    attributes: []
    track_path: "",
    caption: "",
}
                    </pre>
    
                    <pre class="pre-container">
<b>Track label for associating objects' IDs through time</b>
1, 1, xl, yt, w, h, 1, 1, 1
1, 2, xl, yt, w, h, 1, 1, 1
1, 3, xl, yt, w, h, 1, 1, 1
2, 1, xl, yt, w, h, 1, 1, 1
2, 2, xl, yt, w, h, 1, 1, 1
2, 3, xl, yt, w, h, 1, 1, 1
3, 1, xl, yt, w, h, 1, 1, 1
3, 2, xl, yt, w, h, 1, 1, 1
3, 3, xl, yt, w, h, 1, 1, 1
                        </pre>
               </div>
        </div>
        
        <div class="image-json-container">
            <img src="media/dataset-airplane.jpg" alt="Image 1" class="image-dataset">
            <pre class="json-dataset">
                <b>video:</b> "airplane-1",
                <b>label:</b>{
                    &nbsp;&nbsp;&nbsp;&nbsp;<b>class_name:</b> "helicopter",
                    &nbsp;&nbsp;&nbsp;&nbsp;<b>class_synonyms:</b>["airplane", "aircraft", "jet", "plane"],
                    &nbsp;&nbsp;&nbsp;&nbsp;<b>definition:</b> "a vehicle designed for flight in the air",
                    &nbsp;&nbsp;&nbsp;&nbsp;<b>include_attributes:</b> ["black", "flying"],
                    &nbsp;&nbsp;&nbsp;&nbsp;<b>exclude_attributes:</b> [],
                    &nbsp;&nbsp;&nbsp;&nbsp;<b>caption:</b> "Track all black flying helicopters",
                    &nbsp;&nbsp;&nbsp;&nbsp;<b>track_path:</b> "airplane_01.txt"
                }
            </pre>
          </div>

          <div class="image-json-container">
            <img src="media/dataset-car.jpg" alt="Image 1" class="image-dataset">
            <pre class="json-dataset">
              <b>video:</b> "car-1"
              <b>label:</b>{
                  &nbsp;&nbsp;&nbsp;&nbsp;<b>class_name:</b> "car",
                  &nbsp;&nbsp;&nbsp;&nbsp;<b>class_synonyms:</b> ["vehicle", "automobile", "auto", "transport", "transportation"],
                  &nbsp;&nbsp;&nbsp;&nbsp;<b>definition:</b> "mechanical device designed for transportation, powered by an engine or motor, equipped by four wheels",
                  &nbsp;&nbsp;&nbsp;&nbsp;<b>include_attributes: </b> ["white headlight", "oncoming traffic"],
                  &nbsp;&nbsp;&nbsp;&nbsp;<b>exclude_attributes: </b> ["red taillight", "opposite traffic"],
                  &nbsp;&nbsp;&nbsp;&nbsp;<b>caption: </b> "Track white headlight cars while excluding red taillight cars",
                  &nbsp;&nbsp;&nbsp;&nbsp;<b>track_path:</b> "car_01.txt",
              }
            </pre>
          </div>
        </p>
    </div>

    <footer>
        <div class="footer-content">
            <p style="text-align: center;">&copy; Website for ACCV2024's submission</p>
        </div>
    </footer>
</body>